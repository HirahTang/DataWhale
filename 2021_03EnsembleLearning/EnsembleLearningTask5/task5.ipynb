{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用sklearn构建完整的分类项目"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以Iris为例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "feature = iris.feature_names\n",
    "data = pd.DataFrame(X,columns=feature)\n",
    "data['target'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = datasets.load_wine()\n",
    "X_wine = wine.data\n",
    "y_wine = wine.target\n",
    "feature = wine.feature_names\n",
    "data_wine = pd.DataFrame(X_wine,columns=feature)\n",
    "data_wine['target'] = y_wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some additional notes over the confusion matrix:\n",
    "\n",
    "Precision = TP/(TP + FP), which means the the percentage of correct predictions out of all the positive predicionts\n",
    "\n",
    "Recall = TP / (TP + FN), which means how much percentage of positive cases are correctly predicted out of all the positive cases.\n",
    "\n",
    "F1 score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "F1 score is the harmonic mean of Recall and Precision, the aim of using the harmonic mean is that it would be high only if all the components are of high values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC aims to tune the threshold values of classifiers, it can also work as the method to compare the performances of different classifiers\n",
    "\n",
    "More info about ROC curve and AUC score:\n",
    "\n",
    "https://www.youtube.com/watch?v=4jRBRDbJemM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Classic Classification Algorithms:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "Self explanative - apply a logistic functino over a linear regression formula\n",
    "\n",
    "一个小扩展： 逻辑回归不适用于高维高稀疏性的数据，面对这样分布的数据，可以通过施密特正交化后的数据进行建模提高逻辑回归模型的表现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "## Support Vector Machine\n",
    "\n",
    "## Decision Tree\n",
    "\n",
    "## Neural Networks\n",
    "\n",
    "are all classic machine learning classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
